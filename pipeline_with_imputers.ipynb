{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "\n",
    "import feature_selection\n",
    "import sampling\n",
    "\n",
    "reload(feature_selection)\n",
    "reload(sampling)\n",
    "\n",
    "from feature_selection import select_common_features\n",
    "from sampling import create_stratified_kfolds, create_stratified_train_test_sets\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, ComplementNB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score, \\\n",
    "    matthews_corrcoef, mean_squared_error, r2_score, roc_auc_score, roc_curve, auc\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from summarytools import dfSummary\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from imblearn.pipeline import Pipeline as Pipeline_imb\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks\n",
    "\n",
    "# Impute missing values\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, KNNImputer, SimpleImputer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPORARY\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook parameters\n",
    "input_dataset_path = \"data/heart_disease_health_indicators_BRFSS2015.csv\"\n",
    "target_col = \"HeartDiseaseorAttack\"\n",
    "separator = ','\n",
    "\n",
    "generate_new_folds = False\n",
    "n_splits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_imbalanced_dataset = True\n",
    "use_oversampling = True\n",
    "use_undersampling = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputing_method = 'mean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_saving_directory = 'models/2SMOTE_no_imputer_15pct'\n",
    "datasets_with_nans_dir = 'missing_values_folds_15pct'\n",
    "datasets_with_imputed_values_dir = 'missing_values_folds_15pct/median_imputer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_pred: np.array, y_test: pd.Series):\n",
    "    \"\"\" Calculate model quality metrics based on \n",
    "        expected label values from testing dataset (y_test) and predicted values.\n",
    "    \"\"\"\n",
    "    tn, fp, fn, tp = calculate_test_results_from_confusion_matrix(y_test, y_pred)\n",
    "    model_precision = precision_score(y_test, y_pred)\n",
    "    model_recall = recall_score(y_test, y_pred)\n",
    "    model_specificity = specificity_score(tn, fp)\n",
    "    model_acc = accuracy_score(y_test, y_pred)\n",
    "    model_npv = calculate_npv(tn, fn)\n",
    "\n",
    "    model_f1_score = f1_score(y_test, y_pred)\n",
    "    model_mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "    model_r2 = r2_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    model_scores = {\n",
    "        \"True_Negative\": tn,\n",
    "        \"False_Positive\": fp,\n",
    "        \"False_Negative\": fn,\n",
    "        \"True_Positive\": tp,\n",
    "        \"Precision_PPV\": model_precision,\n",
    "        \"Sensitivity_TPR_Recall\": model_recall,\n",
    "        \"Speciticity_TNR\": model_specificity,\n",
    "        \"Accuracy\": model_acc,\n",
    "        \"Negative_Predictive_Value_NPV\": model_npv,\n",
    "        \"F1_Score\": model_f1_score,\n",
    "        \"RMSE\": rmse,\n",
    "        \"R_Squared\": model_r2,\n",
    "        \"Matthews_Correlation_Coefficient_MCC\": model_mcc,\n",
    "        \"ROC_AUC_score\": roc_auc\n",
    "    }\n",
    "\n",
    "    model_scores_df = pd.DataFrame(model_scores.values(), index=model_scores.keys()).transpose()\n",
    "\n",
    "    return model_scores_df\n",
    "\n",
    "def calculate_test_results_from_confusion_matrix(y_test: pd.DataFrame, y_pred: pd.DataFrame):\n",
    "    \"\"\" Calculate the confusion matrix and extract TP, FP, TN, FN from that matrix \"\"\"\n",
    "    conf_matrix = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "    return tn, fp, fn, tp\n",
    "\n",
    "def specificity_score(tn: float, fp: float):\n",
    "    return tn / (tn + fp)\n",
    "\n",
    "def calculate_npv(tn: float, fn: float):\n",
    "    return tn / (tn + fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read folds that are available\n",
    "# Create empty lists to store train and test DataFrames\n",
    "train_datasets = []\n",
    "test_datasets = []\n",
    "\n",
    "for fold_num in range(1, n_splits+1):\n",
    "    train_file_path = f\"{datasets_with_nans_dir}/fold_{fold_num}_train.csv\"\n",
    "    test_file_path = f\"{datasets_with_nans_dir}/fold_{fold_num}_test.csv\"\n",
    "    \n",
    "    # Load the train and test fold data into DataFrames\n",
    "    train_fold = pd.read_csv(train_file_path)\n",
    "    test_fold = pd.read_csv(test_file_path)\n",
    "    \n",
    "    train_datasets.append(train_fold)\n",
    "    test_datasets.append(test_fold)\n",
    "print(\"Folds data were loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = ['GenHlth', 'PhysHlth', 'Age', 'HighChol', 'Diabetes', 'Income', 'HighBP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if imputing_method == 'mean' or imputing_method == 'median':\n",
    "    imputer_obj = SimpleImputer(strategy=imputing_method)\n",
    "elif imputing_method == 'knn':\n",
    "    imputer_obj = KNNImputer(n_neighbors=3)\n",
    "else:\n",
    "    imputer_obj = IterativeImputer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_copy = []\n",
    "for fold_num, (train_data, test_data) in enumerate(zip(train_datasets, test_datasets),1):\n",
    "    train_fold_copy = train_data.copy(deep=True)\n",
    "    train_data_copy.append(train_fold_copy)\n",
    "    train_data = imputer_obj.fit_transform(train_data)\n",
    "\n",
    "    # Save each fold as a CSV file\n",
    "    pd.DataFrame(train_data, columns=train_fold_copy.columns).to_csv(f'{datasets_with_imputed_values_dir}/fold_{fold_num}_train.csv', index=False)\n",
    "    test_data.to_csv(f'{datasets_with_imputed_values_dir}/fold_{fold_num}_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read folds that are available\n",
    "# Create empty lists to store train and test DataFrames\n",
    "train_datasets = []\n",
    "test_datasets = []\n",
    "\n",
    "for fold_num in range(1, n_splits+1):\n",
    "    train_file_path = f\"{datasets_with_imputed_values_dir}/fold_{fold_num}_train.csv\"\n",
    "    test_file_path = f\"{datasets_with_imputed_values_dir}/fold_{fold_num}_test.csv\"\n",
    "    \n",
    "    # Load the train and test fold data into DataFrames\n",
    "    train_fold = pd.read_csv(train_file_path)\n",
    "    test_fold = pd.read_csv(test_file_path)\n",
    "    \n",
    "    train_datasets.append(train_fold)\n",
    "    test_datasets.append(test_fold)\n",
    "print(\"Folds data were loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression(multi_class='multinomial',\n",
    "                          solver='newton-cg',\n",
    "                          random_state=1)\n",
    "clflr2 = LogisticRegression()\n",
    "clf2 = KNeighborsClassifier(algorithm='ball_tree',\n",
    "                            leaf_size=50)\n",
    "clf3 = DecisionTreeClassifier(criterion='gini', random_state=1)\n",
    "clf4 = SVC(kernel=\"linear\", C=0.3, random_state=1)\n",
    "clf5 = RandomForestClassifier(random_state=1)\n",
    "clf6 = XGBClassifier(objective= 'binary:logistic',\n",
    "                    nthread=4,\n",
    "                    seed=42)\n",
    "clf7 = GaussianNB()\n",
    "# clf8 = SVC(gamma='scale', class_weight='balanced')\n",
    "clf9 = LinearSVC(class_weight='balanced')\n",
    "clf10 = DecisionTreeClassifier(criterion='entropy', random_state=42, class_weight='balanced')\n",
    "clf11 = RandomForestClassifier(random_state=1, class_weight='balanced')\n",
    "clf12 = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "clf13 = ComplementNB(force_alpha=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fix_imbalanced_dataset and use_oversampling:\n",
    "    sampler = SMOTE(random_state=42)\n",
    "    # sampler = RandomOverSampler(random_state=42)\n",
    "elif fix_imbalanced_dataset and use_undersampling:\n",
    "    # sampler = TomekLinks()\n",
    "    sampler = SMOTETomek(tomek=TomekLinks(sampling_strategy='majority'))\n",
    "    # sampler = RandomUnderSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fix_imbalanced_dataset:\n",
    "    pipe1 = Pipeline_imb([('sampler', sampler),\n",
    "                          ('scaler', StandardScaler()),\n",
    "                          ('LR', clf1)])\n",
    "    \n",
    "    pipelr2 = Pipeline_imb([('sampler', sampler),\n",
    "                          ('scaler', StandardScaler()),\n",
    "                          ('LR2', clflr2)])\n",
    "\n",
    "    pipe2 = Pipeline_imb([('sampler', sampler),\n",
    "                          ('scaler', StandardScaler()),\n",
    "                          ('KNN', clf2)])\n",
    "    \n",
    "    pipe3 = Pipeline_imb([('sampler', sampler),\n",
    "                          ('DT', clf3)])\n",
    "\n",
    "    pipe4 = Pipeline_imb([('sampler', sampler),\n",
    "                          ('scaler', StandardScaler()),\n",
    "                          ('SVM', clf4)])\n",
    "    \n",
    "    pipe5 = Pipeline_imb([('sampler', sampler),\n",
    "                          ('RF', clf5)])\n",
    "\n",
    "    pipe6 = Pipeline_imb([('sampler', sampler),\n",
    "                          ('XGB', clf6)])\n",
    "\n",
    "    pipe7 = Pipeline_imb([('sampler', sampler),\n",
    "                          ('scaler', StandardScaler()),\n",
    "                          ('GNB', clf7)])\n",
    "    \n",
    "    # pipe8 = Pipeline_imb([('sampler', sampler),\n",
    "    #                       ('scaler', StandardScaler()),\n",
    "    #                       ('bSVC', clf8)])\n",
    "    \n",
    "    pipe9 = Pipeline_imb([('sampler', sampler),\n",
    "                          ('scaler', StandardScaler()),\n",
    "                          ('LSCV', clf9)])\n",
    "    \n",
    "    pipe10 = Pipeline_imb([('sampler', sampler),\n",
    "                          ('bDT', clf10)])\n",
    "    \n",
    "    pipe11 = Pipeline_imb([('sampler', sampler),\n",
    "                          ('bRF', clf11)])\n",
    "    \n",
    "    pipe12 = Pipeline_imb([('sampler', sampler),\n",
    "                          ('scaler', StandardScaler()),\n",
    "                          ('bLR', clf12)])\n",
    "    \n",
    "    pipe13 = Pipeline_imb([('sampler', sampler),\n",
    "                          ('scaler', StandardScaler()),\n",
    "                          ('CNB', clf13)])\n",
    "\n",
    "else:\n",
    "    # Building the pipelines based on pre defined classifiers\n",
    "    pipe1 = Pipeline([('scaler', StandardScaler()),\n",
    "                    ('LR', clf1)])\n",
    "    \n",
    "    pipelr2 = Pipeline([('scaler', StandardScaler()),\n",
    "                          ('LR2', clflr2)])\n",
    "\n",
    "    pipe2 = Pipeline([('scaler', StandardScaler()),\n",
    "                    ('KNN', clf2)])\n",
    "    \n",
    "    pipe3 = Pipeline([('DT', clf3)])\n",
    "\n",
    "    pipe4 = Pipeline([('scaler', StandardScaler()),\n",
    "                    ('SVM', clf4)])\n",
    "    \n",
    "    pipe5 = Pipeline([('RF', clf5)])\n",
    "\n",
    "    pipe6 = Pipeline([('XGB', clf6)])\n",
    "\n",
    "    pipe7 = Pipeline([('scaler', StandardScaler()),\n",
    "                    ('GNB', clf7)])\n",
    "    \n",
    "    # pipe8 = Pipeline([('scaler', StandardScaler()),\n",
    "    #                       ('bSVC', clf8)])\n",
    "    \n",
    "    pipe9 = Pipeline([('scaler', StandardScaler()),\n",
    "                          ('LSCV', clf9)])\n",
    "    \n",
    "    pipe10 = Pipeline([('bDT', clf10)])\n",
    "    \n",
    "    pipe11 = Pipeline([('bRF', clf11)])\n",
    "    \n",
    "    pipe12 = Pipeline([('scaler', StandardScaler()),\n",
    "                          ('bLR', clf12)])\n",
    "    \n",
    "    pipe13 = Pipeline([('scaler', MinMaxScaler()),\n",
    "                       ('CNB', clf13)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results_df_lst = []\n",
    "\n",
    "for fold_num, (train_data, test_data) in enumerate(zip(train_datasets, test_datasets),1):\n",
    "\n",
    "    # # ########## Take 2:1 ratio of negative to positive class #########################\n",
    "\n",
    "    # positive_class_df = train_data[train_data[target_col]==1]\n",
    "    # negative_class_df = train_data[train_data[target_col]==0]\n",
    "\n",
    "    # positive_class_samples_count = len(positive_class_df)\n",
    "    # negative_class_samples_count = 2*positive_class_samples_count\n",
    "\n",
    "    # randomly_selected_negative_class_samples = negative_class_df.sample(n=negative_class_samples_count, random_state=42)\n",
    "    \n",
    "    # preselected_train_data = pd.concat([positive_class_df, randomly_selected_negative_class_samples], axis=0)\n",
    "    # preselected_train_data = preselected_train_data.sample(frac=1.0, ignore_index=True)\n",
    "\n",
    "    # # ################################################################################\n",
    "\n",
    "    fX_train = train_data.drop(columns=[target_col])[best_features]\n",
    "    fy_train = train_data[target_col]\n",
    "\n",
    "    fX_test = test_data.drop(columns=[target_col])[best_features]\n",
    "    fy_test = test_data[target_col]\n",
    "\n",
    "    fold_results = []\n",
    "\n",
    "    for est, name in zip((pipe1, pipelr2, pipe3, pipe5, pipe6, pipe7, pipe2, pipe9, pipe10, pipe11, pipe12), ('LR', 'LR2', 'DT', 'RF', 'XGB', 'GNB', 'KNN', 'LSCV', 'bDT', 'bRF', 'bLR')):\n",
    "        est.fit(X=fX_train, y=fy_train)\n",
    "        fy_pred = est.predict(X=fX_test)\n",
    "\n",
    "        # Create a directory if it doesn't exist\n",
    "        if not os.path.exists(f'{models_saving_directory}/{name}'):\n",
    "            os.makedirs(f'{models_saving_directory}/{name}')\n",
    "\n",
    "        with open(f'{models_saving_directory}/{name}/{name}_model_fold_no{fold_num}.pickle', 'wb') as file:\n",
    "            pickle.dump(est.named_steps[name], file)\n",
    "\n",
    "        est_scores_df = calculate_metrics(y_test=fy_test, y_pred=fy_pred)\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(fy_test, fy_pred)\n",
    "        roc_auc = roc_auc_score(fy_test, fy_pred)\n",
    "\n",
    "        # Plot the ROC curve\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'Receiver Operating Characteristic (ROC) Curve for {name}')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.show()\n",
    "\n",
    "        est_scores_df['model_name'] = name\n",
    "        est_scores_df.to_excel(f'{models_saving_directory}/{name}/{name}_model_result_fold_no{fold_num}.xlsx')\n",
    "        print(f'Log: {name} finished')\n",
    "\n",
    "        fold_results.append(est_scores_df)\n",
    "\n",
    "    fold_results_df = pd.concat(fold_results, ignore_index=True)\n",
    "    fold_results_df['fold no'] = fold_num\n",
    "\n",
    "    model_results_df_lst.append(fold_results_df)\n",
    "    \n",
    "    print(f'Fold no: {fold_num} finished')\n",
    "    print(50 * '-', '\\n')\n",
    "\n",
    "fs_model_results_df = pd.concat(model_results_df_lst, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "fs_model_results_df.to_excel(f'{models_saving_directory}/models_results_{timestamp}.xlsx', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{models_saving_directory}/used_features_{timestamp}.txt', \"w\") as file:\n",
    "    for item in fX_train.columns:\n",
    "        file.write(str(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_model_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate ROC curve for LR, GNB and XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results_df_lst = []\n",
    "\n",
    "# Create empty lists to store ROC data for each fold\n",
    "all_fpr = []\n",
    "all_tpr = []\n",
    "all_thresholds = []\n",
    "\n",
    "for fold_num, (train_data, test_data) in enumerate(zip(train_datasets, test_datasets),1):\n",
    "\n",
    "    fX_train = train_data.drop(columns=[target_col])[best_features]\n",
    "    fy_train = train_data[target_col]\n",
    "\n",
    "    fX_test = test_data.drop(columns=[target_col])[best_features]\n",
    "    fy_test = test_data[target_col]\n",
    "\n",
    "    fold_results = []\n",
    "\n",
    "    for est, name in zip((pipe1, pipe6, pipe7), ('LR', 'XGB', 'GNB')):\n",
    "        est.fit(X=fX_train, y=fy_train)\n",
    "        fy_pred = est.predict_proba(X=fX_test)\n",
    "        # Extract the probability estimates for the positive class (class 1)\n",
    "        y_probabilities_positive = fy_pred[:, 1]\n",
    "\n",
    "        # Create a directory if it doesn't exist\n",
    "        if not os.path.exists(f'{models_saving_directory}/{name}'):\n",
    "            os.makedirs(f'{models_saving_directory}/{name}')\n",
    "\n",
    "        with open(f'{models_saving_directory}/{name}/{name}_model_fold_no{fold_num}.pickle', 'wb') as file:\n",
    "            pickle.dump(est.named_steps[name], file)\n",
    "\n",
    "        if name == 'GNB':\n",
    "            fpr, tpr, thresholds = roc_curve(fy_test, y_probabilities_positive)\n",
    "            roc_auc = roc_auc_score(fy_test, y_probabilities_positive)\n",
    "\n",
    "            all_fpr.append(fpr)\n",
    "            all_tpr.append(tpr)\n",
    "            all_thresholds.append(thresholds)\n",
    "\n",
    "        print(f'Log: {name} finished')\n",
    "    \n",
    "    print(f'Fold no: {fold_num} finished')\n",
    "    print(50 * '-', '\\n')\n",
    "\n",
    "# Combine all thresholds from different folds\n",
    "combined_thresholds = [item for sublist in all_thresholds for item in sublist]\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(len(all_fpr)):\n",
    "    plt.plot(all_fpr[i], all_tpr[i], label=f'Fold {i + 1}', alpha=0.5)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(f'Krzywa ROC dla 10-fold√≥w')\n",
    "plt.legend(loc='lower right')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magisterka",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
