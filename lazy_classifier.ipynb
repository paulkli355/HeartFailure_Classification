{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import openpyxl\n",
    "\n",
    "from data_preprocessing import encode_categorical_features\n",
    "from sampling import create_stratified_kfolds\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, RFE, SelectFromModel, f_classif, mutual_info_classif, chi2, RFE\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score, \\\n",
    "    matthews_corrcoef, mean_squared_error, r2_score, roc_auc_score, roc_curve, auc\n",
    "from math import sqrt\n",
    "\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook parameters\n",
    "input_dataset_path = \"data/heart_disease_health_indicators_BRFSS2015.csv\"\n",
    "target_col = \"HeartDiseaseorAttack\"\n",
    "generate_new_folds = False\n",
    "n_splits = 5\n",
    "k_best_features = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_pred: np.array, y_test: pd.Series):\n",
    "    \"\"\" Calculate model quality metrics based on \n",
    "        expected label values from testing dataset (y_test) and predicted values.\n",
    "    \"\"\"\n",
    "    tn, fp, fn, tp = calculate_test_results_from_confusion_matrix(y_test, y_pred)\n",
    "    model_precision = precision_score(y_test, y_pred)\n",
    "    model_recall = recall_score(y_test, y_pred) # sensitivity\n",
    "    model_specificity = specificity_score(tn, fp)\n",
    "    model_acc = accuracy_score(y_test, y_pred)\n",
    "    model_npv = calculate_npv(tn, fn)\n",
    "\n",
    "    model_f1_score = f1_score(y_test, y_pred)\n",
    "    model_mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "    model_r2 = r2_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "\n",
    "    model_scores = {\n",
    "        \"True_Negative\": tn,\n",
    "        \"False_Positive\": fp,\n",
    "        \"False_Negative\": fn,\n",
    "        \"True_Positive\": tp,\n",
    "        \"Precision_PPV\": model_precision,\n",
    "        \"Sensitivity_TPR_Recall\": model_recall,\n",
    "        \"Speciticity_TNR\": model_specificity,\n",
    "        \"Accuracy\": model_acc,\n",
    "        \"Negative_Predictive_Value_NPV\": model_npv,\n",
    "        \"F1_Score\": model_f1_score,\n",
    "        \"RMSE\": rmse,\n",
    "        \"R_Squared\": model_r2,\n",
    "        \"Matthews_Correlation_Coefficient_MCC\": model_mcc,\n",
    "        \"Threshold_from_ROC_Curve\": list(thresholds),\n",
    "        \"False_Positive_Rate_FPR\": list(fpr),\n",
    "        \"ROC_AUC_score\": roc_auc\n",
    "    }\n",
    "\n",
    "    return model_scores\n",
    "\n",
    "def calculate_test_results_from_confusion_matrix(y_test: pd.DataFrame, y_pred: pd.DataFrame):\n",
    "    \"\"\" Calculate the confusion matrix and extract TP, FP, TN, FN from that matrix \"\"\"\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "    return tn, fp, fn, tp\n",
    "\n",
    "def specificity_score(tn: float, fp: float):\n",
    "    return tn / (tn + fp)\n",
    "\n",
    "def calculate_npv(tn: float, fn: float):\n",
    "    return tn / (tn + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_xml(dictionary, root_name='root'):\n",
    "    root = ET.Element(root_name)\n",
    "    for key, value in dictionary.items():\n",
    "        if isinstance(value, dict):\n",
    "            root.append(dict_to_xml(value, key))\n",
    "        else:\n",
    "            element = ET.Element(key)\n",
    "            element.text = str(value)\n",
    "            root.append(element)\n",
    "    return root\n",
    "\n",
    "\n",
    "def save_dict_to_xml(dictionary, file_path, root_name='root'):\n",
    "    root = dict_to_xml(dictionary, root_name)\n",
    "    tree = ET.ElementTree(root)\n",
    "    with open(file_path, 'wb') as file:\n",
    "        tree.write(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HeartDiseaseorAttack  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0                     0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1                     0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2                     0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3                     0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4                     0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "\n",
       "   Diabetes  PhysActivity  Fruits  ...  AnyHealthcare  NoDocbcCost  GenHlth  \\\n",
       "0       0.0           0.0     0.0  ...            1.0          0.0      5.0   \n",
       "1       0.0           1.0     0.0  ...            0.0          1.0      3.0   \n",
       "2       0.0           0.0     1.0  ...            1.0          1.0      5.0   \n",
       "3       0.0           1.0     1.0  ...            1.0          0.0      2.0   \n",
       "4       0.0           1.0     1.0  ...            1.0          0.0      2.0   \n",
       "\n",
       "   MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  Income  \n",
       "0      18.0      15.0       1.0  0.0   9.0        4.0     3.0  \n",
       "1       0.0       0.0       0.0  0.0   7.0        6.0     1.0  \n",
       "2      30.0      30.0       1.0  0.0   9.0        4.0     8.0  \n",
       "3       0.0       0.0       0.0  0.0  11.0        3.0     6.0  \n",
       "4       3.0       0.0       0.0  0.0  11.0        5.0     4.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_df = pd.read_csv(input_dataset_path)\n",
    "heart_df[target_col] = heart_df[target_col].astype(int)\n",
    "heart_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dataset has 253680 rows and 22 colums\n",
      "Input dataset consists of 21 features and 1 target column\n",
      "Target values are: [0 1]\n",
      "Input dataset contains 23899 duplicated rows and 229781 unique rows\n"
     ]
    }
   ],
   "source": [
    "# general dataset descriptors\n",
    "print(f\"Input dataset has {heart_df.shape[0]} rows and {heart_df.shape[1]} colums\")\n",
    "print(f\"Input dataset consists of {heart_df.drop(columns=[target_col]).shape[1]} features and 1 target column\")\n",
    "\n",
    "print(f\"Target values are: {heart_df[target_col].unique()}\")\n",
    "print(f\"Input dataset contains {heart_df[heart_df.duplicated()].shape[0]} duplicated rows and {heart_df[heart_df.duplicated()==False].shape[0]} unique rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 253680 entries, 0 to 253679\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   HeartDiseaseorAttack  253680 non-null  int32  \n",
      " 1   HighBP                253680 non-null  float64\n",
      " 2   HighChol              253680 non-null  float64\n",
      " 3   CholCheck             253680 non-null  float64\n",
      " 4   BMI                   253680 non-null  float64\n",
      " 5   Smoker                253680 non-null  float64\n",
      " 6   Stroke                253680 non-null  float64\n",
      " 7   Diabetes              253680 non-null  float64\n",
      " 8   PhysActivity          253680 non-null  float64\n",
      " 9   Fruits                253680 non-null  float64\n",
      " 10  Veggies               253680 non-null  float64\n",
      " 11  HvyAlcoholConsump     253680 non-null  float64\n",
      " 12  AnyHealthcare         253680 non-null  float64\n",
      " 13  NoDocbcCost           253680 non-null  float64\n",
      " 14  GenHlth               253680 non-null  float64\n",
      " 15  MentHlth              253680 non-null  float64\n",
      " 16  PhysHlth              253680 non-null  float64\n",
      " 17  DiffWalk              253680 non-null  float64\n",
      " 18  Sex                   253680 non-null  float64\n",
      " 19  Age                   253680 non-null  float64\n",
      " 20  Education             253680 non-null  float64\n",
      " 21  Income                253680 non-null  float64\n",
      "dtypes: float64(21), int32(1)\n",
      "memory usage: 41.6 MB\n"
     ]
    }
   ],
   "source": [
    "heart_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all duplicated values within the dataset\n",
    "heart_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordinal Categorical Features: []\n",
      "Nominal Categorical Features: []\n"
     ]
    }
   ],
   "source": [
    "# encode categorical features using LabelEncoder and OneHotEncoding\n",
    "heart_df = encode_categorical_features(heart_df, target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide a heart failure dataset into features and target value sets\n",
    "x = heart_df.drop(columns=[target_col])\n",
    "y = heart_df[target_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data stratified sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folds data were loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# if needed generare and save into CSV files new folds created by stratified data sampling\n",
    "if generate_new_folds:\n",
    "    create_stratified_kfolds(x_df=x, y_df=y, dataset=heart_df, n_splits=n_splits)\n",
    "\n",
    "# Read folds that are available\n",
    "# Create empty lists to store train and test DataFrames\n",
    "train_datasets = []\n",
    "test_datasets = []\n",
    "\n",
    "for fold_num in range(1, n_splits+1):\n",
    "    train_file_path = f\"folds/fold_{fold_num}_train.csv\"\n",
    "    test_file_path = f\"folds/fold_{fold_num}_test.csv\"\n",
    "    \n",
    "    # Load the train and test fold data into DataFrames\n",
    "    train_fold = pd.read_csv(train_file_path)\n",
    "    test_fold = pd.read_csv(test_file_path)\n",
    "    \n",
    "    train_datasets.append(train_fold)\n",
    "    test_datasets.append(test_fold)\n",
    "print(\"Folds data were loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Random_Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Decision_Tree\": DecisionTreeClassifier(random_state=11, criterion=\"entropy\"),\n",
    "    \"Pruning_Decision_Tree\": DecisionTreeClassifier(random_state=11, ccp_alpha=0.02, criterion=\"entropy\"),\n",
    "    \"Logistic_Regression\": LogisticRegression(random_state=0, C=10, penalty=\"l2\"),\n",
    "    \"Support_Vector_Machine\": SVC(kernel=\"linear\", C=0.3),\n",
    "    \"K_Nearest_Neighbours\": KNeighborsClassifier(leaf_size=1, n_neighbors=3),\n",
    "    \"Gaussian_Naive_Bayes\": GaussianNB(),\n",
    "    \"XGBoost_Classifier\": XGBClassifier(n_estimators=2, max_depth=2, learning_rate=1, objective=\"binary:logistic\")\n",
    "    # ,\"CatBoost_Classifier\": CatBoostClassifier(verbose=False)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory for the folds if it doesn't exist\n",
    "if not os.path.exists('model_results'):\n",
    "    os.makedirs('model_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pklimanek\\Anaconda3\\envs\\magisterka\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "folds_results = {}\n",
    "\n",
    "for fold_num, (train_data, test_data) in enumerate(zip(train_datasets, test_datasets),1):\n",
    "    # Standardize features using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(train_data.drop(target_col, axis=1))\n",
    "    X_test_scaled = scaler.transform(test_data.drop(target_col, axis=1))\n",
    "\n",
    "    # Feature Selection using SelectKBest with ANOVA F-statistic\n",
    "    selector = SelectKBest(score_func=f_classif, k=k_best_features)\n",
    "    X_train_selected = selector.fit_transform(X_train_scaled, train_data[target_col])\n",
    "    X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "    models_results_dict = {}\n",
    "    # Model Building\n",
    "    for model_name, model in models.items():\n",
    "        # train model\n",
    "        model.fit(X_train_selected, train_data[target_col])\n",
    "\n",
    "        # Model Evaluation (e.g., accuracy score)\n",
    "        y_pred = model.predict(X_test_selected)\n",
    "        model_scores = calculate_metrics(y_test=test_data[target_col], y_pred=y_pred)\n",
    "        models_results_dict[model_name] = model_scores\n",
    "\n",
    "    # Add the selected feature names or indices to the dictionary\n",
    "    models_results_dict[\"selected_features\"] = list(x.columns[selector.get_support()])\n",
    "\n",
    "    folds_results[f\"fold_{fold_num}\"] = models_results_dict\n",
    "\n",
    "# fclassif_results_df = pd.DataFrame.from_dict(folds_results) \n",
    "# fclassif_results_df.to_csv(f\"model_results/f_classif_feature_selection_{k_best_features}best.csv\", index=False, header=True)\n",
    "\n",
    "# fclassif_results_df = pd.DataFrame(folds_results)\n",
    "# fclassif_results_df.to_excel(f\"model_results/f_classif_feature_selection_{k_best_features}best.xlsx\", header=True, index=False)\n",
    "\n",
    "save_dict_to_xml(folds_results, f\"model_results/f_classif_feature_selection_{k_best_features}best.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pklimanek\\Anaconda3\\envs\\magisterka\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pklimanek\\Anaconda3\\envs\\magisterka\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pklimanek\\Anaconda3\\envs\\magisterka\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pklimanek\\Anaconda3\\envs\\magisterka\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pklimanek\\Anaconda3\\envs\\magisterka\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pklimanek\\Anaconda3\\envs\\magisterka\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pklimanek\\Anaconda3\\envs\\magisterka\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pklimanek\\Anaconda3\\envs\\magisterka\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pklimanek\\Anaconda3\\envs\\magisterka\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pklimanek\\Anaconda3\\envs\\magisterka\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pklimanek\\Anaconda3\\envs\\magisterka\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pklimanek\\Anaconda3\\envs\\magisterka\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pklimanek\\Anaconda3\\envs\\magisterka\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pklimanek\\Anaconda3\\envs\\magisterka\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pklimanek\\Anaconda3\\envs\\magisterka\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "folds_results = {}\n",
    "\n",
    "for fold_num, (train_data, test_data) in enumerate(zip(train_datasets, test_datasets),1):\n",
    "    # Standardize features using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(train_data.drop(target_col, axis=1))\n",
    "    X_test_scaled = scaler.transform(test_data.drop(target_col, axis=1))\n",
    "\n",
    "    # Feature Selection Mutual Information (MI): This score function measures the dependence between two random variables. \n",
    "    # It is a good choice when you want to capture both linear and non-linear relationships between features and the target variable.\n",
    "    selector = SelectKBest(score_func=mutual_info_classif, k=k_best_features)\n",
    "    X_train_selected = selector.fit_transform(X_train_scaled, train_data[target_col])\n",
    "    X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "    models_results_dict = {}\n",
    "    # Model Building\n",
    "    for model_name, model in models.items():\n",
    "        # train model\n",
    "        model.fit(X_train_selected, train_data[target_col])\n",
    "\n",
    "        # Model Evaluation (e.g., accuracy score)\n",
    "        y_pred = model.predict(X_test_selected)\n",
    "        model_scores = calculate_metrics(y_test=test_data[target_col], y_pred=y_pred)\n",
    "        models_results_dict[model_name] = model_scores\n",
    "\n",
    "    # Add the selected feature names or indices to the dictionary\n",
    "    models_results_dict[\"selected_features\"] = list(x.columns[selector.get_support()])\n",
    "    \n",
    "    folds_results[f\"fold_{fold_num}\"] = models_results_dict\n",
    "\n",
    "# mutual_info_results_df = pd.DataFrame.from_dict(folds_results) \n",
    "# mutual_info_results_df.to_csv(f\"model_results/mutual_info_feature_selection_{k_best_features}best.csv\", index=False, header=True)\n",
    "\n",
    "# mutual_info_results_df = pd.DataFrame(folds_results)\n",
    "# mutual_info_results_df.to_excel(f\"model_results/mutual_info_feature_selection_{k_best_features}best.xlsx\", header=True, index=False)\n",
    "\n",
    "save_dict_to_xml(folds_results, f\"model_results/mutual_info_feature_selection_{k_best_features}best.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pklimanek\\Anaconda3\\envs\\magisterka\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pklimanek\\Anaconda3\\envs\\magisterka\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pklimanek\\Anaconda3\\envs\\magisterka\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pklimanek\\Anaconda3\\envs\\magisterka\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pklimanek\\Anaconda3\\envs\\magisterka\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pklimanek\\Anaconda3\\envs\\magisterka\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pklimanek\\Anaconda3\\envs\\magisterka\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pklimanek\\Anaconda3\\envs\\magisterka\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pklimanek\\Anaconda3\\envs\\magisterka\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pklimanek\\Anaconda3\\envs\\magisterka\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "folds_results = {}\n",
    "\n",
    "for fold_num, (train_data, test_data) in enumerate(zip(train_datasets, test_datasets),1):\n",
    "    # Standardize features using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(train_data.drop(target_col, axis=1))\n",
    "    X_test_scaled = scaler.transform(test_data.drop(target_col, axis=1))\n",
    "\n",
    "    # Feature Selection Recursive Feature Elimination (RFE): RFE is an iterative feature selection method that recursively removes the least significant features. \n",
    "    # It is particularly useful when a prior model (e.g., logistic regression, SVM) in mind.\n",
    "    selector = RFE(estimator=LogisticRegression(), n_features_to_select=k_best_features)\n",
    "    X_train_selected = selector.fit_transform(X_train_scaled, train_data[target_col])\n",
    "    X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "    models_results_dict = {}\n",
    "    # Model Building\n",
    "    for model_name, model in models.items():\n",
    "        # train model\n",
    "        model.fit(X_train_selected, train_data[target_col])\n",
    "\n",
    "        # Model Evaluation (e.g., accuracy score)\n",
    "        y_pred = model.predict(X_test_selected)\n",
    "        model_scores = calculate_metrics(y_test=test_data[target_col], y_pred=y_pred)\n",
    "        models_results_dict[model_name] = model_scores\n",
    "\n",
    "    # Add the selected feature names or indices to the dictionary\n",
    "    models_results_dict[\"selected_features\"] = list(x.columns[selector.get_support()])\n",
    "    \n",
    "    folds_results[f\"fold_{fold_num}\"] = models_results_dict\n",
    "\n",
    "# RFE_results_df = pd.DataFrame.from_dict(folds_results) \n",
    "# RFE_results_df.to_csv(f\"model_results/RFE_feature_selection_{k_best_features}best.csv\", index=False, header=True)\n",
    "\n",
    "# RFE_results_df = pd.DataFrame(folds_results)\n",
    "# RFE_results_df.to_excel(f\"model_results/RFE_feature_selection_{k_best_features}best.xlsx\", header=True, index=False)\n",
    "\n",
    "save_dict_to_xml(folds_results, f\"model_results/RFE_feature_selection_{k_best_features}best.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_results = {}\n",
    "for fold_num, (train_data, test_data) in enumerate(zip(train_datasets, test_datasets),1):\n",
    "    # Standardize features using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(train_data.drop(target_col, axis=1))\n",
    "    X_test_scaled = scaler.transform(test_data.drop(target_col, axis=1))\n",
    "\n",
    "    # Feature Selection Feature Importance from Tree-based Models: For ensemble tree-based models like Random Forest or XGBoost, you can use feature importances to select the most important features.\n",
    "    selector = SelectFromModel(RandomForestClassifier(), max_features=k_best_features)\n",
    "    X_train_selected = selector.fit_transform(X_train_scaled, train_data[target_col])\n",
    "    X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "    models_results_dict = {}\n",
    "    # Model Building\n",
    "    for model_name, model in models.items():\n",
    "        # train model\n",
    "        model.fit(X_train_selected, train_data[target_col])\n",
    "\n",
    "        # Model Evaluation (e.g., accuracy score)\n",
    "        y_pred = model.predict(X_test_selected)\n",
    "        model_scores = calculate_metrics(y_test=test_data[target_col], y_pred=y_pred)\n",
    "        models_results_dict[model_name] = model_scores\n",
    "\n",
    "    # Add the selected feature names or indices to the dictionary\n",
    "    models_results_dict[\"selected_features\"] = list(x.columns[selector.get_support()])\n",
    "    \n",
    "    folds_results[f\"fold_{fold_num}\"] = models_results_dict\n",
    "\n",
    "# tree_feature_importance_results_df = pd.DataFrame.from_dict(folds_results) \n",
    "# tree_feature_importance_results_df.to_csv(f\"model_results/tree_feature_importance_feature_selection_{k_best_features}best.csv\", index=False, header=True)\n",
    "\n",
    "# tree_feature_importance_results_df = pd.DataFrame(folds_results)\n",
    "# tree_feature_importance_results_df.to_excel(f\"model_results/tree_feature_importance_feature_selection_{k_best_features}best.xlsx\", header=True, index=False)\n",
    "\n",
    "save_dict_to_xml(folds_results, f\"model_results/tree_feature_importance_feature_selection_{k_best_features}best.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import SelectFromModel\n",
    "# from sklearn.linear_model import Lasso\n",
    "\n",
    "# folds_results = {}\n",
    "# for fold_num, (train_data, test_data) in enumerate(zip(train_datasets, test_datasets),1):\n",
    "#     # Standardize features using StandardScaler\n",
    "#     scaler = StandardScaler()\n",
    "#     X_train_scaled = scaler.fit_transform(train_data.drop(target_col, axis=1))\n",
    "#     X_test_scaled = scaler.transform(test_data.drop(target_col, axis=1))\n",
    "\n",
    "#     # Feature Selection L1-based feature selection: L1 regularization methods like Lasso can be used for feature selection. Features with zero coefficients can be pruned.\n",
    "#     selector = SelectFromModel(Lasso(), max_features=k_best_features)\n",
    "#     X_train_selected = selector.fit_transform(X_train_scaled, train_data[target_col])\n",
    "#     X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "#     models_results_dict = {}\n",
    "#     # Model Building\n",
    "#     for model_name, model in models.items():\n",
    "#         # train model\n",
    "#         model.fit(X_train_selected, train_data[target_col])\n",
    "\n",
    "#         # Model Evaluation (e.g., accuracy score)\n",
    "#         y_pred = model.predict(X_test_selected)\n",
    "#         model_scores = calculate_metrics(y_test=test_data[target_col], y_pred=y_pred)\n",
    "#         models_results_dict[model_name] = model_scores\n",
    "\n",
    "#     folds_results[f\"fold_{fold_num}\"] = models_results_dict\n",
    "\n",
    "# lasso_results_df = pd.DataFrame.from_dict(folds_results) \n",
    "# lasso_results_df.to_csv(\"model_evaluation_results_lasso_feature_selection.csv\", index=False, header=True)\n",
    "\n",
    "# lasso_results_df = pd.DataFrame(folds_results)\n",
    "# lasso_results_df.to_excel(\"model_evaluation_results_lasso_feature_selection.xlsx\", header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folds_results = {}\n",
    "# \n",
    "# for fold_num, (train_data, test_data) in enumerate(zip(train_datasets, test_datasets),1):\n",
    "#     # Standardize features using StandardScaler\n",
    "#     scaler = StandardScaler()\n",
    "#     X_train_scaled = scaler.fit_transform(train_data.drop(target_col, axis=1))\n",
    "#     X_test_scaled = scaler.transform(test_data.drop(target_col, axis=1))\n",
    "\n",
    "#     # Feature Selection Chi-Squared (χ²): Chi-squared tests can be used for feature selection when dealing with categorical data. \n",
    "#     # It measures the dependency between variables and is particularly useful for feature selection in classification tasks with categorical features.\n",
    "#     selector = SelectKBest(score_func=chi2, k=k_best_features)\n",
    "#     X_train_selected = selector.fit_transform(X_train_scaled, train_data[target_col])\n",
    "#     X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "#     models_results_dict = {}\n",
    "#     # Model Building\n",
    "#     for model_name, model in models.items():\n",
    "#         # train model\n",
    "#         model.fit(X_train_selected, train_data[target_col])\n",
    "\n",
    "#         # Model Evaluation (e.g., accuracy score)\n",
    "#         y_pred = model.predict(X_test_selected)\n",
    "#         model_scores = calculate_metrics(y_test=test_data[target_col], y_pred=y_pred)\n",
    "#         models_results_dict[model_name] = model_scores\n",
    "    \n",
    "#     folds_results[f\"fold_{fold_num}\"] = models_results_dict\n",
    "\n",
    "# chi2_results_df = pd.DataFrame.from_dict(folds_results) \n",
    "# chi2_results_df.to_csv(\"model_evaluation_results_chi2_feature_selection.csv\", index=False, header=True)\n",
    "\n",
    "# chi2_results_df = pd.DataFrame(folds_results)\n",
    "# chi2_results_df.to_excel(\"model_evaluation_results_chi2_feature_selection.xlsx\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magisterka",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
